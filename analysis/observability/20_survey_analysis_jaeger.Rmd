---
title: "Survey Analysis Jaeger"
author: "Anders Sundelin"
date: "2025-05-04"
output: html_document
params:
    cache: "../.cache"
    output: "../output"
    reloo: FALSE
    cores: 2
    threads: 4
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(ggrepel)
library(forcats)
library(stringr)
library(lubridate)
library(bookdown)
library(ggformula)
library(brms)
library(bayesplot)
library(tidybayes)
library(ggpubr)
```

# Survey Results - Jaeger Evaluation

```{r ingest}
source("ingest_survey_data.R")
raw <- ingest_survey_data("../data/TrainingDayResponses.xlsx")
jaeger <- jaeger_data(raw)
```

## EDA

```{r}
jaeger_usable <- get_jaeger_usable(jaeger)
jaeger_ease_of_use <- get_jaeger_ease_of_use(jaeger)
jaeger_accessible <- get_jaeger_accessible(jaeger)
jaeger_intent <- get_jaeger_intend_use(jaeger)
```

```{r}
rbind(jaeger_usable |> mutate(trait="usable", rate=usable) |> select(trait, site, rate),
      jaeger_ease_of_use |> mutate(trait="ease-of-use", rate=ease_of_use) |> select(trait, site, rate),
      jaeger_accessible |> mutate(trait="accessible", rate=accessible) |> select(trait, site, rate),
      jaeger_intent |> mutate(trait="intent-to-use", rate=intent) |> select(trait, site, rate)
      ) |> group_by(trait) |> ggplot(aes(x=as.numeric(rate), fill=site)) +
      geom_histogram(stat="count", position="dodge") +
  scale_x_continuous(name="rating", breaks = 1:7, labels = c("Extremely\nLikely", "Quite\nLikely", "Slightly\nLikely", "Neutral", "Slightly\nUnlikely", "Quite\nUnlikely", "Extremely\nUnlikely") ) +
  facet_wrap(~trait, ncol=2) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

# Jaeger Usability

## Model 1 (Population-level intercept-only)

```{r}
d <- jaeger_usable |> select(usable)
formula <- usable | thres(6) ~ 1
priors <- c(prior(normal(-1.068, 1), class = Intercept, coef = 1),
            prior(normal(-0.566, 1), class = Intercept, coef = 2),
            prior(normal(-0.180, 1), class = Intercept, coef = 3),
            prior(normal( 0.180, 1), class = Intercept, coef = 4),
            prior(normal( 0.566, 1), class = Intercept, coef = 5),
            prior(normal( 1.068, 1), class = Intercept, coef = 6))
validate_prior(prior = priors,
               data=d,
               family=cumulative(probit),
               formula=formula)
```
### Prior predictive checks M1

```{r m1_ppc}
M1_ppc <- brm(
  data = d,
  family = cumulative(probit),
  formula=formula,
  prior = priors,
  drop_unused_levels = F,
  sample_prior = "only",
  backend="cmdstanr",
  warmup = 1000,
  iter  = ITERATIONS,
  chains = CHAINS,
  cores = CORES,
  seed = 1
)
```

No divergent transitions using those priors.

```{r}
pp_check(M1_ppc, type = "bars",
         ndraws = 500, size = 1/2, fatten = 3/2)
```

Prior predictive checks look good, as expected.

```{r m1}
M1 <- brm(
  data = d,
  family = cumulative(probit),
  formula=formula,
  prior = priors,
  drop_unused_levels = F,
  backend="cmdstanr",
  warmup = 1000,
  iter  = ITERATIONS,
  chains = CHAINS,
  cores = CORES,
  seed = 1,
  control = list(adapt_delta=0.99)
)
```

No divergent transitions when reducing the step size a bit (there were two with the default 0.95 `adapt_delta`).
Let's do the posterior checks

```{r}
m <- M1
```


```{r}
p <- mcmc_trace(m)
pars <- levels(p[["data"]][["parameter"]])
plots <- seq(1, to=length(pars), by=6)
lapply(plots, function(i) {
  start <- i
  end <- start+5
  mcmc_trace(m, pars = na.omit(pars[start:end]))
  })
```

The chains seem to mix well. The disc is flat as the width (variance) of the latent variable is fixed in this model.

```{r}
mcmc_plot(m, type="rhat")
mcmc_plot(m, type="rhat_hist")
mcmc_plot(m, type="neff")
mcmc_plot(m, type="neff_hist")
```

Some $N_{eff}$ values are slightly below 0.5, but well above 0.1

```{r}
loo <- loo(m)
loo
plot(loo)
```

No problems with the estimated LOO values.

## Posterior predictive checks

```{r}
pp_check(M1, type = "bars",
         ndraws = 500, size = 1/2, fatten = 3/2)
```

Our model fits the data well, and has proper small probabilities on the lowest values.

```{r}
summary(M1)
```

```{r}
plot_M1_latent_distribution(M1, "usable")
```

```{r}
plot_M1_posterior_mean(M1, "usability", usable_mean, limits=c(1,7))
```

```{r}
jaeger_usable |> summarise(mean(as.numeric(usable)))
```

Sample mean is quite in the middle between Quite Likely and Slightly Likely.

## Site-specific, no pooling

```{r}
d <- jaeger_usable |> select(usable, site)
formula <- usable | thres(6) ~ 1 + site
priors <- c(prior(normal(-1.068, 1), class = Intercept, coef = 1),
            prior(normal(-0.566, 1), class = Intercept, coef = 2),
            prior(normal(-0.180, 1), class = Intercept, coef = 3),
            prior(normal( 0.180, 1), class = Intercept, coef = 4),
            prior(normal( 0.566, 1), class = Intercept, coef = 5),
            prior(normal( 1.068, 1), class = Intercept, coef = 6),
            prior(normal(0, 1), class = b))
validate_prior(prior = priors,
               data=d,
               family=cumulative(probit),
               formula=formula)
```

```{r m2_ppc}
M2_ppc <- brm(
  data = d,
  family = cumulative(probit),
  formula=formula,
  prior = priors,
  drop_unused_levels = F,
  sample_prior = "only",
  backend="cmdstanr",
  warmup = 1000,
  iter  = ITERATIONS,
  chains = CHAINS,
  cores = CORES,
  seed = 1
)
m <- M2_ppc
```

One divergent transition, but as this is the prior predictive checks, this does not matter too much.
Perhaps our new beta prior is a bit too broad, but the data should tame it.

```{r}
pp_check(M2_ppc, type = "bars",
         ndraws = 500, size = 1/2, fatten = 3/2)
```

Priors looking good, all values are present.

```{r m2}
M2 <- brm(
  data = d,
  family = cumulative(probit),
  formula=formula,
  prior = priors,
  drop_unused_levels = F,
  backend="cmdstanr",
  warmup = 1000,
  iter  = ITERATIONS,
  chains = CHAINS,
  cores = CORES,
  seed = 1,
  control = list(adapt_delta=0.99)
)
m <- M2
```

The default step size 0.95 cause one divergent transition, so we decrease it a bit to 0.99.

```{r}
p <- mcmc_trace(m)
pars <- levels(p[["data"]][["parameter"]])
plots <- seq(1, to=length(pars), by=6)
lapply(plots, function(i) {
  start <- i
  end <- start+5
  mcmc_trace(m, pars = na.omit(pars[start:end]))
  })
```

Good mix of chains, and `disc` is still flat, as the variance of the latent variable is fixed

```{r}
mcmc_plot(m, type="rhat")
mcmc_plot(m, type="rhat_hist")
mcmc_plot(m, type="neff")
mcmc_plot(m, type="neff_hist")
```

Good diagnostics, only one $N_{eff}$ value slightly above 0.4.

```{r}
pp_check(m, type = "bars", ndraws = 500, size = 1/2, fatten = 3/2)
```

```{r}
plot_M2_latent_distribution(m, "usability")
```

A slight shift in distribution, but overall very similar ratings for Europe and India.

```{r}
plot_M2_posterior_mean(m, "usability", usable_mean, limits=c(1,7))
```

The shift is visible in the posterior expected mean value also.
India tends slightly more towards SL (also in the sample mean).

```{r}
d |> group_by(site, usable) |> tally()
```

And here we see the reason---although both Europe and India have some SU responses, in Europe, there are 14 more Extremely Likely responses (versus no XL at all in India).

```{r}
d |> group_by(site) |> summarize(mean(as.numeric(usable)))
```

Sample means also reflect this change.

# Multilevel site, pooling on respondent

```{r}
d <- jaeger_usable |> select(usable, site, id)
formula <- usable | thres(6) ~ 1 + site + (1 | id)
priors <- c(prior(normal(-1.068, 1), class = Intercept, coef = 1),
            prior(normal(-0.566, 1), class = Intercept, coef = 2),
            prior(normal(-0.180, 1), class = Intercept, coef = 3),
            prior(normal( 0.180, 1), class = Intercept, coef = 4),
            prior(normal( 0.566, 1), class = Intercept, coef = 5),
            prior(normal( 1.068, 1), class = Intercept, coef = 6),
            prior(normal(0, 1), class = b),
            prior(exponential(5), class = sd))
validate_prior(prior = priors,
               data=d,
               family=cumulative(probit),
               formula=formula)

```

```{r m3_ppc}
M3_ppc <- brm(
  data = d,
  family = cumulative(probit),
  formula = formula,
  prior = priors,
  drop_unused_levels = F,
  sample_prior = "only",
  backend="cmdstanr",
  warmup = 1000,
  iter  = ITERATIONS,
  chains = CHAINS,
  cores = CORES,
  seed = 1
)

```

Three divergent transitions, maybe the priors are a bit wild.
But this is just the prior predictive check.

```{r}
pp_check(M3_ppc, type = "bars",
         ndraws = 500, size = 1/2, fatten = 3/2)
m <- M3_ppc
```

These priors are looking good, all outcomes are possible
How does the groups (respondents) look?

```{r}
pp_check(M3_ppc, type = "bars_grouped", group="id",
         ndraws = 500, size = 1/2, fatten = 3/2)
```

Grouped PPCs are also looking good, we should be able to trust these priors.

```{r m3}
M3 <- brm(
  data = d,
  family = cumulative(probit),
  formula=formula,
  prior = priors,
  drop_unused_levels = F,
  backend="cmdstanr",
  warmup = 1000,
  iter  = ITERATIONS,
  chains = CHAINS,
  cores = CORES,
  seed = 1
)
m <- M3
```

No divergent transitions, even with the default step size of 0.95.

```{r}
p <- mcmc_trace(m)
pars <- levels(p[["data"]][["parameter"]])
plots <- seq(1, to=length(pars), by=6)
lapply(plots, function(i) {
  start <- i
  end <- start+5
  mcmc_trace(m, pars = na.omit(pars[start:end]))
  })
```

These caterpillars look good, and the `disc` continues to be flat, as it is fixed at 1.

```{r}
mcmc_plot(m, type="rhat")
mcmc_plot(m, type="rhat_hist")
mcmc_plot(m, type="neff")
mcmc_plot(m, type="neff_hist")
```

$\hat{R}$ are looking good, although some $N_{eff}$ values are low, they still range between 0.2 and 1.0.

```{r}
pp_check(m, type = "bars", ndraws = 500, size = 1/2, fatten = 3/2)
```

Posterior checks look good (although there is a slight bump in expected value at answer 7, perhaps due to overly wild priors that we have not been able to tame).

```{r}
pp_check(m, type = "bars_grouped", group="id", ndraws = 500, size = 1/2, fatten = 3/2)
```

Groups also look good

```{r}
plot_M2_latent_distribution(m, "usability")
```

With the regularizing prior, the respondents tend towards the population mean.
So the highly positive European cohort (which was ranging between XL and QL in M2) are now closer to QL, and the Indian cohort are still a bit more negative.

```{r}
plot_M2_posterior_mean(m, "usability", usable_mean, limits=c(1,7))
```

# Multilevel site, pooling on respondent, variable variance (disc)

```{r}
d <- jaeger_usable |> select(usable, site, id)
formula <- bf(usable | thres(6) ~ 1 + site + (1 | id)) +
           lf(disc              ~ 0 + site, cmc = FALSE)
priors <- c(prior(normal(-1.068, 1), class = Intercept, coef = 1),
            prior(normal(-0.566, 1), class = Intercept, coef = 2),
            prior(normal(-0.180, 1), class = Intercept, coef = 3),
            prior(normal( 0.180, 1), class = Intercept, coef = 4),
            prior(normal( 0.566, 1), class = Intercept, coef = 5),
            prior(normal( 1.068, 1), class = Intercept, coef = 6),
            prior(normal(0, 1), class = b),
            prior(normal(0, log(2)/2), class = b, dpar=disc),
            prior(exponential(5), class = sd)
            )
validate_prior(prior = priors,
               data=d,
               family=cumulative(probit),
               formula=formula)
```
```{r m4_ppc}
M4_ppc <- brm(
  data = d,
  family = cumulative(probit),
  formula=formula,
  prior = priors,
  drop_unused_levels = F,
  sample_prior = "only",
  backend="cmdstanr",
  warmup = 1000,
  iter  = ITERATIONS,
  chains = CHAINS,
  cores = CORES,
  seed = 1,
  control = list(adapt_delta=0.99)
)
m <- M4_ppc
```

No divergent transitions.

```{r}
pp_check(M4_ppc, type = "bars", ndraws = 500, size = 1/2, fatten = 3/2)
```

With these priors, there are actually less difference between the levels.

```{r m4}
M4 <- brm(
  data = d,
  family = cumulative(probit),
  formula=formula,
  prior = priors,
  drop_unused_levels = F,
  backend="cmdstanr",
  warmup = 1000,
  iter  = ITERATIONS,
  chains = CHAINS,
  cores = CORES,
  seed = 1,
  control = list(adapt_delta=0.99),
  init = 0
)
m <- M4
```

To improve sampling efficiency, we limit the starting value to 0 also for the Jaeger track (see AI output for a discussion why this helps efficiency).

```{r}
p <- mcmc_trace(m)
pars <- levels(p[["data"]][["parameter"]])
plots <- seq(1, to=length(pars), by=6)
lapply(plots, function(i) {
  start <- i
  end <- start+5
  mcmc_trace(m, pars = na.omit(pars[start:end]))
  })
```

These caterpillars look good, and `b_disc_siteIndia` also mix well now, as we allow the variance of the latent variable to vary between the sites.

```{r}
mcmc_plot(m, type="rhat")
mcmc_plot(m, type="rhat_hist")
mcmc_plot(m, type="neff")
mcmc_plot(m, type="neff_hist")
```

A few $N_{eff}$ values below 0.5, but all of them above 0.25. Diagnostics look OK.

```{r}
loo(M4)
```

No problems with the LOO-CV values, all Pareto-k values are below 0.7.

```{r}
M4 <- add_criterion(M4, criterion = "loo")
```

```{r}
summary(M4)
```

```{r}
plot_M4_latent_distribution(M4, "usability-varying")
```
```{r}
plot_M4_posterior_mean(M4, "usability-varying", usable_mean, limits=c(1,7))
```

Narrower distribution for the Indian cohort, who also clusters closer towards the middle of the scale.

# Jaeger Ease-of-Use
```{r}
jaeger_ease_of_use <- get_jaeger_ease_of_use(jaeger)
```


```{r}
d <- jaeger_ease_of_use |> select(ease_of_use)
formula <- ease_of_use | thres(6) ~ 1
priors <- c(prior(normal(-1.068, 1), class = Intercept, coef = 1),
            prior(normal(-0.566, 1), class = Intercept, coef = 2),
            prior(normal(-0.180, 1), class = Intercept, coef = 3),
            prior(normal( 0.180, 1), class = Intercept, coef = 4),
            prior(normal( 0.566, 1), class = Intercept, coef = 5),
            prior(normal( 1.068, 1), class = Intercept, coef = 6))
```

```{r e1}
E1 <- brm(
  data = d,
  family = cumulative(probit),
  formula=formula,
  prior = priors,
  drop_unused_levels = F,
  backend="cmdstanr",
  warmup = 1000,    iter  = ITERATIONS,    chains = CHAINS,  cores = CORES,
  seed = 1,
  control = list(adapt_delta=0.99)
)
```

One divergent transition with the default step size, goes away when we reduce the step size to 0.99.

```{r}
m <- E1
```


```{r}
p <- mcmc_trace(m)
pars <- levels(p[["data"]][["parameter"]])
plots <- seq(1, to=length(pars), by=6)
lapply(plots, function(i) {
  start <- i
  end <- start+5
  mcmc_trace(m, pars = na.omit(pars[start:end]))
  })
```

The chains seem to mix well. The disc is flat as the variance is fixed.

```{r}
mcmc_plot(m, type="rhat")
mcmc_plot(m, type="rhat_hist")
mcmc_plot(m, type="neff")
mcmc_plot(m, type="neff_hist")
```

One low $N_{eff}$ value, but overall the diagnostics look OK.

```{r}
( loo <- loo(m) )
plot(loo)
```

```{r}
pp_check(E1, type = "bars", ndraws = 500, size = 1/2, fatten = 3/2)
```

LOO and posterior checks look good

```{r}
pp_check(m, type = "hist", ndraws = 8, binwidth = 1) +
  scale_x_continuous(breaks = 1:7) +
  ggtitle("Example draws from the posterior")
```

```{r}
plot_M1_latent_distribution(m, "ease of use")
```

```{r}
plot_M1_posterior_mean(m, "ease of use", ease_of_use_mean, limits=c(1,7))
```

```{r}
jaeger_ease_of_use |> summarise(mean(as.numeric(ease_of_use)))
```

The sample mean is closer to QL than to SL, as indicated by the dashed line.

## Ease of use per site
```{r}
d <- jaeger_ease_of_use |> select(ease_of_use, site)
formula <- ease_of_use | thres(6) ~ 1 + site
priors <- c(prior(normal(-1.068, 1), class = Intercept, coef = 1),
            prior(normal(-0.566, 1), class = Intercept, coef = 2),
            prior(normal(-0.180, 1), class = Intercept, coef = 3),
            prior(normal( 0.180, 1), class = Intercept, coef = 4),
            prior(normal( 0.566, 1), class = Intercept, coef = 5),
            prior(normal( 1.068, 1), class = Intercept, coef = 6),
            prior(normal(0, 1), class = b))
```

```{r e2}
E2 <- brm(
  data = d,
  family = cumulative(probit),
  formula=formula,
  prior = priors,
  drop_unused_levels = F,
  backend="cmdstanr",
  warmup = 1000,
  iter  = ITERATIONS,
  chains = CHAINS,
  cores = CORES,
  seed = 1,
  control = list(adapt_delta=0.99)
)
m <- E2
```

No divergent transitions when we adjust the step size (2 with the default 0.95).

```{r}
pp_check(m, type = "bars", ndraws = 500, size = 1/2, fatten = 3/2)
```

Posterior checks look good.

```{r}
plot_M2_latent_distribution(m, "ease of use")
```

Slightly less positive answers from the Indian cohort.

```{r}
plot_M2_posterior_mean(m, "ease of use", ease_of_use_mean, limits=c(1,7))
```

This is also visible in the expected mean rating, which is right between QL and SL for the India team, and closer to QL for the European.

## Ease-of-use grouped per respodent

```{r}
d <- jaeger_ease_of_use |> select(ease_of_use, site, id)
formula <- ease_of_use | thres(6) ~ 1 + site + (1 | id)
priors <- c(prior(normal(-1.068, 1), class = Intercept, coef = 1),
            prior(normal(-0.566, 1), class = Intercept, coef = 2),
            prior(normal(-0.180, 1), class = Intercept, coef = 3),
            prior(normal( 0.180, 1), class = Intercept, coef = 4),
            prior(normal( 0.566, 1), class = Intercept, coef = 5),
            prior(normal( 1.068, 1), class = Intercept, coef = 6),
            prior(normal(0, 1), class = b),
            prior(exponential(5), class = sd))
```
```{r e3}
E3 <- brm(
  data = d,
  family = cumulative(probit),
  formula=formula,
  prior = priors,
  drop_unused_levels = F,
  backend="cmdstanr",
  warmup = 1000,
  iter  = ITERATIONS,
  chains = CHAINS,
  cores = CORES,
  seed = 1
)
m <- E3
```

No divergent transitions.

```{r}
summary(E3)
```


```{r}
p <- mcmc_trace(m)
pars <- levels(p[["data"]][["parameter"]])
plots <- seq(1, to=length(pars), by=6)
lapply(plots, function(i) {
  start <- i
  end <- start+5
  mcmc_trace(m, pars = na.omit(pars[start:end]))
  })
```
These caterpillars look good, and the `disc` continues to be flat, as it is fixed at 1.

```{r}
mcmc_plot(m, type="rhat")
mcmc_plot(m, type="rhat_hist")
mcmc_plot(m, type="neff")
mcmc_plot(m, type="neff_hist")
```

A bit more lower $N_{eff}$ values, but lowest is still close to 0.25.

```{r}
pp_check(m, type = "bars", ndraws = 500, size = 1/2, fatten = 3/2)
```

```{r}
pp_check(m, type = "bars_grouped", group="id",
         ndraws = 500, size = 1/2, fatten = 3/2)
```

Posterior checks look OK, both on population level and per respondent (group).

```{r}
plot_M2_latent_distribution(m, "ease-of-use")
```

```{r}
plot_M2_posterior_mean(m, "ease-of-use", ease_of_use_mean, limits=c(1,7))
```

Both Europe and India are now slightly closer to the population mean.
Which is caused by the regularizing prior (grouping on respondent).

## Ease-of-use, pooled on respondent, varying variance per site
```{r}
d <- jaeger_ease_of_use |> select(ease_of_use, site, id)
formula <- bf(ease_of_use | thres(6) ~ 1 + site + (1 | id)) +
           lf(disc                   ~ 0 + site, cmc = FALSE)
priors <- c(prior(normal(-1.068, 1), class = Intercept, coef = 1),
            prior(normal(-0.566, 1), class = Intercept, coef = 2),
            prior(normal(-0.180, 1), class = Intercept, coef = 3),
            prior(normal( 0.180, 1), class = Intercept, coef = 4),
            prior(normal( 0.566, 1), class = Intercept, coef = 5),
            prior(normal( 1.068, 1), class = Intercept, coef = 6),
            prior(normal(0, 1), class = b),
            prior(normal(0, log(2)/2), class = b, dpar=disc),
            prior(exponential(5), class = sd)
            )
validate_prior(prior = priors,
               data=d,
               family=cumulative(probit),
               formula=formula)
```

```{r e4}
E4 <- brm(
  data = d,
  family = cumulative(probit),
  formula=formula,
  prior = priors,
  drop_unused_levels = F,
  backend="cmdstanr",
  warmup = 1000,
  iter  = ITERATIONS,
  chains = CHAINS,
  cores = CORES,
  seed = 1,
  control = list(adapt_delta=0.99),
  init = 0
)
m <- E4
```

Adjusting the stepsize and initial value removes the divergent transitions.

```{r}
p <- mcmc_trace(m)
pars <- levels(p[["data"]][["parameter"]])
plots <- seq(1, to=length(pars), by=6)
lapply(plots, function(i) {
  start <- i
  end <- start+5
  mcmc_trace(m, pars = na.omit(pars[start:end]))
  })
```

These caterpillars look good, and the `b_disc_siteIndia` also mixes well.

```{r}
mcmc_plot(m, type="rhat")
mcmc_plot(m, type="rhat_hist")
mcmc_plot(m, type="neff")
mcmc_plot(m, type="neff_hist")
```

Lowest $N_{eff}$ value is still around 0.25.
But overall diagnostics look good.

```{r}
summary(E4)
```

```{r}
plot_M4_latent_distribution(E4, "ease-of-use")

```

Indian distribution is narrower, with less variance.

```{r}
plot_M4_posterior_mean(E4, "ease-of-use-varying", ease_of_use_mean, limits=c(1,7))
```

## Accessibility

```{r}
jaeger_accessible <- get_jaeger_accessible(jaeger)
```

```{r}
d <- jaeger_accessible |> select(accessible)
formula <- accessible | thres(6) ~ 1
priors <- c(prior(normal(-1.068, 1), class = Intercept, coef = 1),
            prior(normal(-0.566, 1), class = Intercept, coef = 2),
            prior(normal(-0.180, 1), class = Intercept, coef = 3),
            prior(normal( 0.180, 1), class = Intercept, coef = 4),
            prior(normal( 0.566, 1), class = Intercept, coef = 5),
            prior(normal( 1.068, 1), class = Intercept, coef = 6))

```

```{r a1}
A1 <- brm(
  data = d,
  family = cumulative(probit),
  formula=formula,
  prior = priors,
  drop_unused_levels = F,
  backend="cmdstanr",
  warmup = 1000,
  iter  = ITERATIONS,
  chains = CHAINS,
  cores = CORES,
  seed = 1,
  control = list(adapt_delta=0.99)
)
```

Adjusting the step size removes the single divergent transition that is caused by the default step size of 0.95.

```{r}
pp_check(A1, type = "bars", ndraws = 500, size = 1/2, fatten = 3/2)
```

```{r}
summary(A1)
```

```{r}
plot(loo(A1))
```

All LOO values are OK, well below 0.7.

```{r}
m <- A1
p <- mcmc_trace(m)
pars <- levels(p[["data"]][["parameter"]])
plots <- seq(1, to=length(pars), by=6)
lapply(plots, function(i) {
  start <- i
  end <- start+5
  mcmc_trace(m, pars = na.omit(pars[start:end]))
  })
```

The chains seem to mix well. The disc is flat as the variance is fixed.

```{r}
mcmc_plot(m, type="rhat")
mcmc_plot(m, type="rhat_hist")
mcmc_plot(m, type="neff")
mcmc_plot(m, type="neff_hist")
```

Diagnostics also look OK.

```{r}
plot_M1_latent_distribution(A1, "accessible")
```
```{r}
plot_M1_posterior_mean(A1, "accessible", accessible_mean, limits=c(1,7))
```

Distribution and expected posterior mean also looks OK, we will use these figures as example of how cumulative probit models work.

```{r}
(
  left_p <- plot_M1_latent_distribution(A1, "usable") + ggtitle(NULL) + scale_x_continuous(expression(phi*(z)), breaks = -3:3,
                       sec.axis = dup_axis(
                         name = NULL,
                         breaks = fixef(A1)[1:6, 1] |> as.double(),
                         labels = parse(text = str_c("tau[", 1:6, "]"))
                         ))

)
(
  right_p <- plot_M1_posterior_mean(A1, "usability", accessible_mean, limits=c(1,4)) + ggtitle(NULL, NULL) + scale_x_continuous(limits=c(1,4), breaks = 1:7, labels=c("1 - XL", "2 - QL", "3 - SL", "4 - N", "5 - SUL", "6 - QUL", "7 - XUL"))
)

```
```{r}
(
  p <- ggarrange(left_p, right_p, labels=c("a)", "b)"), nrow=1)
)
```

```{r}
fixef(A1)[1:6, 1]
```

```{r}
pnorm(-1.4056)
```
```{r}
pnorm(0.2259607)-pnorm(-1.4056749)
pnorm(3)-pnorm(-3)
```

```{r}
figsave("../output/cum_probit_metrics.pdf", p, device=cairo_pdf, width=15, height=5, units="cm")
```

```{r}
expected_value_M1(A1)
```


```{r}
jaeger_accessible |> summarise(mean(as.numeric(accessible)))
```

### Accessible by site


```{r}
d <- jaeger_accessible |> select(accessible, site)
formula <- accessible | thres(6) ~ 1 + site
priors <- c(prior(normal(-1.068, 1), class = Intercept, coef = 1),
            prior(normal(-0.566, 1), class = Intercept, coef = 2),
            prior(normal(-0.180, 1), class = Intercept, coef = 3),
            prior(normal( 0.180, 1), class = Intercept, coef = 4),
            prior(normal( 0.566, 1), class = Intercept, coef = 5),
            prior(normal( 1.068, 1), class = Intercept, coef = 6),
            prior(normal(0, 1), class = b))
```

```{r a2}
A2 <- brm(
  data = d,
  family = cumulative(probit),
  formula=formula,
  prior = priors,
  drop_unused_levels = F,
  backend="cmdstanr",
  warmup = 1000,
  iter  = ITERATIONS,
  chains = CHAINS,
  cores = CORES,
  seed = 1,
  control = list(adapt_delta=0.99)
)
m <- A2
```

Adjusting the step size fixes the single divergent transition present when using the default step size of 0.95.

```{r}
p <- mcmc_trace(m)
pars <- levels(p[["data"]][["parameter"]])
plots <- seq(1, to=length(pars), by=6)
lapply(plots, function(i) {
  start <- i
  end <- start+5
  mcmc_trace(m, pars = na.omit(pars[start:end]))
  })
```


```{r}
mcmc_plot(m, type="rhat")
mcmc_plot(m, type="rhat_hist")
mcmc_plot(m, type="neff")
mcmc_plot(m, type="neff_hist")
```

The lowest $N_{eff}$ value is 0.4, and the rest of the diagnostics are also OK.

```{r}
pp_check(m, type = "bars", ndraws = 500, size = 1/2, fatten = 3/2)
```

```{r}
plot_M2_latent_distribution(A2, "accessibility")

```
```{r}
plot_M2_posterior_mean(A2, "accessibility", accessible_mean, limits=c(1,7))
```

Very similar distributions for the two sites, and this is also confirmed by the data:

```{r}
d |> group_by(site, accessible) |> tally()
```

### Accessible, grouped by individual

```{r}
d <- jaeger_accessible |> select(accessible, site, id)
formula <- accessible | thres(6) ~ 1 + site + (1 | id)
priors <- c(prior(normal(-1.068, 1), class = Intercept, coef = 1),
            prior(normal(-0.566, 1), class = Intercept, coef = 2),
            prior(normal(-0.180, 1), class = Intercept, coef = 3),
            prior(normal( 0.180, 1), class = Intercept, coef = 4),
            prior(normal( 0.566, 1), class = Intercept, coef = 5),
            prior(normal( 1.068, 1), class = Intercept, coef = 6),
            prior(normal(0, 1), class = b),
            prior(exponential(5), class = sd))
validate_prior(prior = priors,
               data=d,
               family=cumulative(probit),
               formula=formula)

```


```{r a3}
A3 <- brm(
  data = d,
  family = cumulative(probit),
  formula=formula,
  prior = priors,
  drop_unused_levels = F,
  backend="cmdstanr",
  warmup = 1000,
  iter  = ITERATIONS,
  chains = CHAINS,
  cores = CORES,
  seed = 1,
  control = list(adapt_delta=0.99)
)
m <- A3
```

The single divergent transition present with the default step size is fixed by reducing the step size to 0.99.

```{r}
p <- mcmc_trace(m)
pars <- levels(p[["data"]][["parameter"]])
plots <- seq(1, to=length(pars), by=6)
lapply(plots, function(i) {
  start <- i
  end <- start+5
  mcmc_trace(m, pars = na.omit(pars[start:end]))
  })
```


```{r}
mcmc_plot(m, type="rhat")
mcmc_plot(m, type="rhat_hist")
mcmc_plot(m, type="neff")
mcmc_plot(m, type="neff_hist")
```

There are a few low $N_{eff}$ values, two around 0.2, and some around 0.4. But overall, the diagnostics look good.

```{r}
pp_check(A3, type = "bars", ndraws = 500, size = 1/2, fatten = 3/2)
```

```{r}
pp_check(A3, type = "bars_grouped", group="id",
         ndraws = 500, size = 1/2, fatten = 3/2)
```

```{r}
plot_M2_latent_distribution(A3, "accessibility")
```

```{r}
plot_M2_posterior_mean(A3, "accessibility", accessible_mean, limits=c(1,7))
```

Very similar distributions, also when grouping per respondent.

## Accessibility, pooled on respondent, varying variance per site
```{r}
d <- jaeger_accessible |> select(accessible, site, id)
formula <- bf(accessible | thres(6) ~ 1 + site + (1 | id)) +
           lf(disc                   ~ 0 + site, cmc = FALSE)
priors <- c(prior(normal(-1.068, 1), class = Intercept, coef = 1),
            prior(normal(-0.566, 1), class = Intercept, coef = 2),
            prior(normal(-0.180, 1), class = Intercept, coef = 3),
            prior(normal( 0.180, 1), class = Intercept, coef = 4),
            prior(normal( 0.566, 1), class = Intercept, coef = 5),
            prior(normal( 1.068, 1), class = Intercept, coef = 6),
            prior(normal(0, 1), class = b),
            prior(normal(0, log(2)/2), class = b, dpar=disc),
            prior(exponential(5), class = sd)
            )
validate_prior(prior = priors,
               data=d,
               family=cumulative(probit),
               formula=formula)
```

```{r a4}
A4 <- brm(
  data = d,
  family = cumulative(probit),
  formula=formula,
  prior = priors,
  drop_unused_levels = F,
  backend="cmdstanr",
  warmup = 1000,
  iter  = ITERATIONS,
  chains = CHAINS,
  cores = CORES,
  seed = 1,
  control = list(adapt_delta=0.99),
  init = 0
)
m <- A4
```

No divergent transitions, when we adjust step size and initial value.

```{r}
p <- mcmc_trace(m)
pars <- levels(p[["data"]][["parameter"]])
plots <- seq(1, to=length(pars), by=6)
lapply(plots, function(i) {
  start <- i
  end <- start+5
  mcmc_trace(m, pars = na.omit(pars[start:end]))
  })
```


```{r}
mcmc_plot(m, type="rhat")
mcmc_plot(m, type="rhat_hist")
mcmc_plot(m, type="neff")
mcmc_plot(m, type="neff_hist")
```


```{r}
pp_check(A4, type = "bars", ndraws = 500, size = 1/2, fatten = 3/2)
```

```{r}
pp_check(A4, type = "bars_grouped", group="id", ndraws = 500, size = 1/2, fatten = 3/2)
```

```{r}
plot_M4_latent_distribution(A4, "accessibility")
```
```{r}
plot_M4_posterior_mean(A4, "accessibility-varying", accessible_mean, limits=c(1,7))
```

Slightly narrower India distribution, but overall very similar (esp. in terms of expected value).

## Intend-to-use

```{r}
jaeger_intent <- get_jaeger_intend_use(jaeger)
```

```{r}
d <- jaeger_intent |> select(intent)
formula <- intent | thres(6) ~ 1
priors <- c(prior(normal(-1.068, 1), class = Intercept, coef = 1),
            prior(normal(-0.566, 1), class = Intercept, coef = 2),
            prior(normal(-0.180, 1), class = Intercept, coef = 3),
            prior(normal( 0.180, 1), class = Intercept, coef = 4),
            prior(normal( 0.566, 1), class = Intercept, coef = 5),
            prior(normal( 1.068, 1), class = Intercept, coef = 6))

```

```{r i1}
I1 <- brm(
  data = d,
  family = cumulative(probit),
  formula=formula,
  prior = priors,
  drop_unused_levels = F,
  backend="cmdstanr",
  warmup = 1000,
  iter  = ITERATIONS,
  chains = CHAINS,
  cores = CORES,
  seed = 1
)
```

No divergent transitions.

```{r}
pp_check(I1, type = "bars", ndraws = 500, size = 1/2, fatten = 3/2)
```

Posterior predictions look good.

```{r}
summary(I1)
```
```{r}
plot(loo(I1))
```

LOO values are good also.

```{r }
m <- I1
p <- mcmc_trace(m)
pars <- levels(p[["data"]][["parameter"]])
plots <- seq(1, to=length(pars), by=6)
lapply(plots, function(i) {
  start <- i
  end <- start+5
  mcmc_trace(m, pars = na.omit(pars[start:end]))
  })
```

The chains seem to mix well. The disc is flat as the variance is fixed.

```{r}
mcmc_plot(m, type="rhat")
mcmc_plot(m, type="rhat_hist")
mcmc_plot(m, type="neff")
mcmc_plot(m, type="neff_hist")
```

No problems with the diagnostics, the lowest $N_{eff}$ value is around 0.3, but most of them are above 0.6--0.8.

```{r}
plot_M1_latent_distribution(I1, "intend-to-use")
```
```{r}
plot_M1_posterior_mean(I1, "intend-to-use", intent_mean, limits=c(1,7))
```

The expected posterior mean is closer to SL than the sample mean.

```{r}
jaeger_intent |> summarise(mean(as.numeric(intent)))
```

## Intent by site

```{r}
d <- jaeger_intent |> select(intent, site)
formula <- intent | thres(6) ~ 1 + site
priors <- c(prior(normal(-1.068, 1), class = Intercept, coef = 1),
            prior(normal(-0.566, 1), class = Intercept, coef = 2),
            prior(normal(-0.180, 1), class = Intercept, coef = 3),
            prior(normal( 0.180, 1), class = Intercept, coef = 4),
            prior(normal( 0.566, 1), class = Intercept, coef = 5),
            prior(normal( 1.068, 1), class = Intercept, coef = 6),
            prior(normal(0, 1), class = b))
```

```{r i2}
I2 <- brm(
  data = d,
  family = cumulative(probit),
  formula=formula,
  prior = priors,
  drop_unused_levels = F,
  backend="cmdstanr",
  warmup = 1000,
  iter  = ITERATIONS,
  chains = CHAINS,
  cores = CORES,
  seed = 1
)
m <- I2
```

No divergent transitions.

```{r}
p <- mcmc_trace(m)
pars <- levels(p[["data"]][["parameter"]])
plots <- seq(1, to=length(pars), by=6)
lapply(plots, function(i) {
  start <- i
  end <- start+5
  mcmc_trace(m, pars = na.omit(pars[start:end]))
  })
```

Chains mix well.

```{r}
mcmc_plot(m, type="rhat")
mcmc_plot(m, type="rhat_hist")
mcmc_plot(m, type="neff")
mcmc_plot(m, type="neff_hist")
```

Diagnostics look OK also.

```{r}
pp_check(m, type = "bars", ndraws = 500, size = 1/2, fatten = 3/2)
```

And the posterior checks also look OK.

```{r}
plot_M2_latent_distribution(I2, "intent-to-use")

```
```{r}
plot_M2_posterior_mean(I2, "intent-to-use", intent_mean, limits=c(1,7))
```

A slight shift towards N for the India respondents.
But very much overlapping distributions, also visible in the posterior expected mean.

```{r}
d |> group_by(site, intent) |> tally()
```

### Intent by site, partial pooled by respondent

```{r}
d <- jaeger_intent |> select(intent, site, id)
formula <- intent | thres(6) ~ 1 + site + (1 | id)
priors <- c(prior(normal(-1.068, 1), class = Intercept, coef = 1),
            prior(normal(-0.566, 1), class = Intercept, coef = 2),
            prior(normal(-0.180, 1), class = Intercept, coef = 3),
            prior(normal( 0.180, 1), class = Intercept, coef = 4),
            prior(normal( 0.566, 1), class = Intercept, coef = 5),
            prior(normal( 1.068, 1), class = Intercept, coef = 6),
            prior(normal(0, 1), class = b),
            prior(exponential(5), class = sd))
validate_prior(prior = priors,
               data=d,
               family=cumulative(probit),
               formula=formula)

```


```{r i3}
I3 <- brm(
  data = d,
  family = cumulative(probit),
  formula=formula,
  prior = priors,
  drop_unused_levels = F,
  backend="cmdstanr",
  warmup = 1000,
  iter  = ITERATIONS,
  chains = CHAINS,
  cores = CORES,
  seed = 1,
  control = list(adapt_delta=0.99)
)
m <- I3
```

Adjusting step size fixes the 7 divergent transitions that occur with the default step size of 0.95.

```{r}
p <- mcmc_trace(m)
pars <- levels(p[["data"]][["parameter"]])
plots <- seq(1, to=length(pars), by=6)
lapply(plots, function(i) {
  start <- i
  end <- start+5
  mcmc_trace(m, pars = na.omit(pars[start:end]))
  })
```

Chains seem to mix well.

```{r}
mcmc_plot(m, type="rhat")
mcmc_plot(m, type="rhat_hist")
mcmc_plot(m, type="neff")
mcmc_plot(m, type="neff_hist")
```

There are quite some low $N_{eff}$ values , but none as low as 0.1 yet.

```{r}
pp_check(I3, type = "bars", ndraws = 500, size = 1/2, fatten = 3/2)
```

```{r}
pp_check(I3, type = "bars_grouped", group="id", ndraws = 500, size = 1/2, fatten = 3/2)
```

```{r}
plot_M2_latent_distribution(I3, "intend-to-use")
```

```{r}
plot_M2_posterior_mean(I3, "intend-to-use", intent_mean, limits=c(1,7))
```

Slightly less positive replies by the Indian cohort.

### Narrower priors (@@@ move to 05_)

```{r}
priors <- c(prior(normal(-1.068, 1), class = Intercept, coef = 1),
            prior(normal(-0.566, 1), class = Intercept, coef = 2),
            prior(normal(-0.180, 1), class = Intercept, coef = 3),
            prior(normal( 0.180, 1), class = Intercept, coef = 4),
            prior(normal( 0.566, 1), class = Intercept, coef = 5),
            prior(normal( 1.068, 1), class = Intercept, coef = 6),
            prior(normal(0, 1), class = b),
            prior(exponential(10), class = sd))
```

```{r i3narrow}
I3narrow <- brm(
  data = d,
  family = cumulative(probit),
  formula=formula,
  prior = priors,
  drop_unused_levels = F,
  backend="cmdstanr",
  warmup = 1000,
  iter  = ITERATIONS,
  chains = CHAINS,
  cores = CORES,
  seed = 1
)
m <- I3narrow
```
```{r}
p <- mcmc_trace(m)
pars <- levels(p[["data"]][["parameter"]])
plots <- seq(1, to=length(pars), by=6)
lapply(plots, function(i) {
  start <- i
  end <- start+5
  mcmc_trace(m, pars = na.omit(pars[start:end]))
  })
```


```{r}
mcmc_plot(m, type="rhat")
mcmc_plot(m, type="rhat_hist")
mcmc_plot(m, type="neff")
mcmc_plot(m, type="neff_hist")
```


```{r}
pp_check(I3narrow, type = "bars",
         ndraws = 500, size = 1/2, fatten = 3/2)
```

```{r}
pp_check(I3narrow, type = "bars_grouped", group="id",
         ndraws = 500, size = 1/2, fatten = 3/2)
```

```{r}
plot_M2_latent_distribution(I3narrow, "intend-narrow")
```

```{r}
plot_M2_posterior_mean(I3narrow, "intend-narrow", intent_mean, limits=c(1,7))
```

## Intent-to-use, pooled on respondent, varying variance per site

```{r}
d <- jaeger_intent |> select(intent, site, id)
formula <- bf(intent | thres(6) ~ 1 + site + (1 | id)) +
           lf(disc              ~ 0 + site, cmc = FALSE)
priors <- c(prior(normal(-1.068, 1), class = Intercept, coef = 1),
            prior(normal(-0.566, 1), class = Intercept, coef = 2),
            prior(normal(-0.180, 1), class = Intercept, coef = 3),
            prior(normal( 0.180, 1), class = Intercept, coef = 4),
            prior(normal( 0.566, 1), class = Intercept, coef = 5),
            prior(normal( 1.068, 1), class = Intercept, coef = 6),
            prior(normal(0, 1), class = b),
            prior(normal(0, log(2)/2), class = b, dpar=disc),
            prior(exponential(5), class = sd)
            )
validate_prior(prior = priors,
               data=d,
               family=cumulative(probit),
               formula=formula)
```

```{r i4}
I4 <- brm(
  data = d,
  family = cumulative(probit),
  formula=formula,
  prior = priors,
  drop_unused_levels = F,
  backend="cmdstanr",
  warmup = 1000,
  iter  = ITERATIONS,
  chains = CHAINS,
  cores = CORES,
  seed = 1,
  control = list(adapt_delta=0.99),
  init = 0
)
m <- I4
```

Adjusting step size and initial sampling value fixes all divergent transitions.

```{r}
p <- mcmc_trace(m)
pars <- levels(p[["data"]][["parameter"]])
plots <- seq(1, to=length(pars), by=6)
lapply(plots, function(i) {
  start <- i
  end <- start+5
  mcmc_trace(m, pars = na.omit(pars[start:end]))
  })
```

Chains mix well, also for the `disc` parameter that now is allowed to vary.

```{r}
mcmc_plot(m, type="rhat")
mcmc_plot(m, type="rhat_hist")
mcmc_plot(m, type="neff")
mcmc_plot(m, type="neff_hist")
```

A few low $N_{eff}$ values, but all are above 0.25, so no issue.

```{r}
pp_check(I4, type = "bars", ndraws = 500, size = 1/2, fatten = 3/2)
```

```{r}
pp_check(I4, type = "bars_grouped", group="id", ndraws = 500, size = 1/2, fatten = 3/2)
```

```{r}
loo(I4)
```

```{r}
I4 <- add_criterion(I4, criterion = "loo")
```

All LOO-CV values are good, Pareto-k < 0.7.

```{r}
plot_M4_latent_distribution(I4, "intent-varying")
```
```{r}
plot_M4_posterior_mean(I4, "intent-varying", intent_mean, limits=c(1,7))
```

The Indian cohort are narrower, more focused on QL and SL.

# Model comparison

## Usability
```{r}
loo(M1, M2, M3, M4)
```

M4 comes out on top, though the differentce is small, M3 is not even one sd away.

## Ease-of-use
```{r}
loo(E1, E2, E3, E4)
```

Similar situation, but reversed, for E3 and E4. Hard to see any difference among them.

## Accessible
```{r}
loo(A1, A2, A3, A4)
```

For accessibility, all four models are essentially equivalent (within one sd of another).

## Intent-to-use
```{r}
loo(I1, I2, I3, I3narrow, I4)
```

For intent-to-use, I4 is best, around 3 sd bettern than I3.

# Expected values

```{r}
expected_value_M4(M4)
expected_value_M4(E4)
expected_value_M4(A4)
expected_value_M4(I4)
```
